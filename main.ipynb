{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait,Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from IPython.display import Image, display\n",
    "from google.colab import output\n",
    "import re\n",
    "import base64\n",
    "import time\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from google.colab import files\n",
    "output.clear()\n",
    "\n",
    "def web_driver():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--verbose\")\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    # options.add_argument(\"--window-size=1920, 1200\")\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "def get_url_and_index(driver):\n",
    "    results = []  # List to store results (index and URL)\n",
    "    while True:\n",
    "        try:\n",
    "            # Wait for the table to be present\n",
    "            WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_element_located((By.ID, 'DataTables_Table_0'))\n",
    "            )\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            table = soup.find('table', id='DataTables_Table_0')\n",
    "            links = table.find_all('a', class_='text-teal-700')\n",
    "\n",
    "            for link in links:\n",
    "                href = link.get('href')\n",
    "                if 'fundamentals' in href:\n",
    "                    href = href.replace('fundamentals', 'stocks')\n",
    "                    full_link = f\"https://chartink.com{href}\"\n",
    "                    results.append(full_link)  # Store the index and URL\n",
    "\n",
    "            # Try to click the next page button\n",
    "            next_button = driver.find_element(By.ID, 'DataTables_Table_0_next')\n",
    "            if 'disabled' in next_button.get_attribute('class'):\n",
    "                break\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
    "            driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"No more pages or an error occurred:\", e)\n",
    "            break\n",
    "\n",
    "    driver.quit()\n",
    "    return results  # Return the list of results\n",
    "\n",
    "\n",
    "def get_image_from_link(url, timeframe, s_range, retries=3):\n",
    "    driver = web_driver()\n",
    "    driver.get(url)\n",
    "\n",
    "    try:\n",
    "        # Capture HTML before switching to iframe\n",
    "        page_html_before_iframe = driver.execute_script(\"return document.documentElement.outerHTML;\")\n",
    "\n",
    "        # Wait for the <select> element and select the value for \"1 year\"\n",
    "        select_element = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.ID, \"ti\"))\n",
    "        )\n",
    "        select_Range_element = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.ID, \"d\"))\n",
    "        )\n",
    "\n",
    "        h3_element = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//h3[@style='margin: 0px;margin-left: 5px;font-size:20px']\"))\n",
    "        )\n",
    "        \n",
    "        # Extract the text of the <h3> element\n",
    "        company_name = h3_element.text\n",
    "        print(f\"Company Name: {company_name}\")\n",
    "\n",
    "        timeframe_mapping = {\n",
    "        \"1 day\": \"1\",\n",
    "        \"2 days\": \"2\",\n",
    "        \"3 days\": \"3\",\n",
    "        \"5 days\": \"5\",\n",
    "        \"10 days\": \"10\",\n",
    "        \"1 month\": \"22\",\n",
    "        \"2 months\": \"44\",\n",
    "        \"3 months\": \"66\",\n",
    "        \"4 months\": \"91\",\n",
    "        \"6 months\": \"121\",\n",
    "        \"9 months\": \"198\",\n",
    "        \"1 year\": \"252\",\n",
    "        \"2 years\": \"504\",\n",
    "        \"3 years\": \"756\",\n",
    "        \"5 years\": \"1008\",\n",
    "        \"8 years\": \"1764\",\n",
    "        \"All Data\": \"5000\"\n",
    "        }\n",
    "        select = Select(select_element)\n",
    "        if timeframe in timeframe_mapping:\n",
    "            select.select_by_value(timeframe_mapping[timeframe])\n",
    "        else:\n",
    "            select.select_by_value(timeframe_mapping[\"All Data\"])\n",
    "\n",
    "        range_mapping = {\n",
    "        \"Daily\": \"d\",\n",
    "        \"Weekly\": \"w\",\n",
    "        \"Monthly\": \"m\",\n",
    "        \"1 Minute\": \"1_minute\",\n",
    "        \"2 Minute\": \"2_minute\",\n",
    "        \"3 Minute\": \"3_minute\",\n",
    "        \"5 Minute\": \"5_minute\",\n",
    "        \"10 Minute\": \"10_minute\",\n",
    "        \"15 Minute\": \"15_minute\",\n",
    "        \"20 Minute\": \"20_minute\",\n",
    "        \"25 Minute\": \"25_minute\",\n",
    "        \"30 Minute\": \"30_minute\",\n",
    "        \"45 Minute\": \"45_minute\",\n",
    "        \"75 Minute\": \"75_minute\",\n",
    "        \"125 Minute\": \"125_minute\",\n",
    "        \"1 Hour\": \"60_minute\",\n",
    "        \"2 Hour\": \"120_minute\",\n",
    "        \"3 Hour\": \"180_minute\",\n",
    "        \"4 Hour\": \"240_minute\"\n",
    "        }\n",
    "\n",
    "        select_Range = Select(select_Range_element)\n",
    "        if s_range in range_mapping:\n",
    "            select_Range.select_by_value(range_mapping[s_range])\n",
    "        else:\n",
    "            select_Range.select_by_value(\"d\")\n",
    "\n",
    "        # Click the update button\n",
    "        update_button = driver.find_element(By.ID, \"innerb\")\n",
    "        update_button.click()\n",
    "\n",
    "        # Wait for the iframe containing the chart to load\n",
    "        iframe = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.ID, \"ChartImage\"))\n",
    "        )\n",
    "        driver.switch_to.frame(iframe)\n",
    "\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                # Capture the HTML inside the iframe\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "                )\n",
    "\n",
    "                body_html = driver.execute_script(\"return document.body.innerHTML;\")\n",
    "\n",
    "                # Check if body_html is empty or None\n",
    "                if not body_html:\n",
    "                    raise ValueError(\"innerHTML is empty or not found\")\n",
    "\n",
    "                # Regex to extract the base64 image data\n",
    "                img_match = re.search(r'<img[^>]*id=\"cross\"[^>]*src=\"data:\\s*image/[^;]+;base64,([^\"]+)\"', body_html)\n",
    "\n",
    "                if img_match:\n",
    "                    # Extract the base64 encoded image data\n",
    "                    img_data_base64 = img_match.group(1)\n",
    "                    return company_name, img_data_base64  # Returning the base64 blob code as string\n",
    "\n",
    "            except Exception as e:\n",
    "                if attempt > 1:\n",
    "                    print(f\"Attempt {attempt + 1} failed: {e}. Retrying...\")\n",
    "                time.sleep(5)  # Wait before retrying\n",
    "\n",
    "        print(\"Failed to find image after multiple attempts. Check the HTML structure or regex.\")\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "      if attempt > 1:\n",
    "        print(f\"Attempt {attempt + 1} failed: {e}. Retrying...\")\n",
    "        time.sleep(5)\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "        \n",
    "def main(Screener_url, Period, Range):\n",
    "    driver = web_driver()\n",
    "    driver.get(Screener_url)\n",
    "    results = get_url_and_index(driver)\n",
    "    output_pdf = \"/content/screener_images.pdf\"\n",
    "    c = canvas.Canvas(output_pdf, pagesize=A4)\n",
    "    a4_width, a4_height = A4\n",
    "    size = len(results)\n",
    "    print(f\"Total number of graphs: {size}\")\n",
    "    for i, url in enumerate(results):\n",
    "      company_name, img_data_base64 = get_image_from_link(url, Period, Range)\n",
    "      img_data = base64.b64decode(img_data_base64)\n",
    "      image = Image.open(BytesIO(img_data))\n",
    "      temp_image_path = f\"/content/temp_image{i}.png\"\n",
    "      image.save(temp_image_path)\n",
    "      image_ratio = image.width / image.height\n",
    "      a4_ratio = a4_width / a4_height\n",
    "      if image_ratio > a4_ratio:\n",
    "          scaled_width = a4_width\n",
    "          scaled_height = a4_width / image_ratio\n",
    "      else:\n",
    "          scaled_height = a4_height\n",
    "          scaled_width = a4_height * image_ratio\n",
    "      page_height = scaled_height + 40\n",
    "      c.setPageSize((a4_width, page_height))\n",
    "      c.setFont(\"Helvetica\", 12)  # Set font and size for the heading\n",
    "      c.drawCentredString(a4_width / 2, page_height - 30, company_name)\n",
    "      x_offset = (a4_width - scaled_width) / 2\n",
    "      y_offset = (page_height - scaled_height - 40) / 2  # Adjust y_offset to fit image below the heading\n",
    "      c.drawImage(temp_image_path, x_offset, y_offset, width=scaled_width, height=scaled_height)\n",
    "      c.showPage() \n",
    "      #   with open(\"image.png\", \"wb\") as img_file:\n",
    "      #     img_file.write(img_data)  \n",
    "\n",
    "      # display(Image(filename=\"image.png\"))\n",
    "    c.save()\n",
    "    output.clear()\n",
    "    files.download(output_pdf)\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title chartink.com to pdf\n",
    "Screener_url = 'https://chartink.com/screener/copy-idea-krishchess-combo-mbsanghavi' # @param {type:\"string\"}\n",
    "Range = \"Weekly\"  # @param [\"Daily\", \"Weekly\", \"Monthly\", \"1 Minute\", \"2 Minute\", \"3 Minute\", \"5 Minute\", \"10 Minute\", \"15 Minute\", \"20 Minute\", \"25 Minute\", \"30 Minute\", \"45 Minute\", \"75 Minute\", \"125 Minute\", \"1 hour\", \"2 hour\", \"3 hour\", \"4 hour\"]\n",
    "Period = \"1 year\"  # @param [\"1 day\", \"2 days\", \"3 days\", \"5 days\", \"10 days\", \"1 month\", \"2 months\", \"3 months\", \"4 months\", \"6 months\", \"9 months\", \"1 year\", \"2 years\", \"3 years\", \"5 years\", \"8 years\", \"All Data\"]\n",
    "\n",
    "main(Screener_url, Period, Range)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
